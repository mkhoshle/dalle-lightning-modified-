
gcloud  beta compute tpus create tpu-1 --zone=europe-west4-a --network=lgai-vision-vpc-network --accelerator-type=v3-32 --version=pytorch-1.8 --reserved

gcloud  beta compute tpus create tpu-1 --zone=europe-west4-a --network=lgai-vision-vpc-network --accelerator-type=v2-8 --version=pytorch-1.8 --reserved
    
gcloud compute instances create tpu-test --zone=europe-west4-a --machine-type=n1-standard-16 --image-family=torch-xla --image-project=ml-images --boot-disk-size=200GB --scopes=https://www.googleapis.com/auth/cloud-platform --project=lgai-vision-tpu --network=lgai-vision-vpc-network


python3 -m torch_xla.distributed.xla_dist --tpu=${TPU_NAME} -- python3 home/taehoon.kim/taming-transformers/main.py --base configs/coco_vqgan.yaml -t True


——————————————————————————————

gcloud services enable tpu.googleapis.com

gcloud alpha compute tpus tpu-vm create tpu-vm-3 --zone=europe-west4-a --accelerator-type=v3-8 --version=v2-alpha 


gcloud alpha compute tpus tpu-vm ssh tpu-vm-1 --zone europe-west4-a --project lgai-vision-tpu

export XRT_TPU_CONFIG="localservice;0;localhost:51011"

python3 -m torch_xla.core.xrt_run_server --port 51011 --restart

python3 main.py --use_tpus

export TF_CPP_VMODULE=tensor=5,computation_client=5,xrt_computation_client=5,aten_xla_type=1 && export TF_CPP_MIN_LOG_LEVEL=0

-------------------------------

python3 -m torch_xla.core.xrt_run_server --port 51011 --restart

sudo /opt/google-cloud-sdk/bin/gcloud components update

export PROJECT_ID=lgai-vision-tpu
export TPU_NAME=tpu-pod-256
export ZONE=europe-west4-a
export RUNTIME_VERSION=v2-alpha

gcloud alpha compute tpus tpu-vm create ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --accelerator-type v3-512 \
--version ${RUNTIME_VERSION}  --reserved 

gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID}


export VM_NAME=pod-ctrl-32
export ZONE=europe-west4-a



gcloud compute config-ssh


gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "git clone --recursive https://github.com/pytorch/xla.git"

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-256 --restart-tpuvm-pod-server -- python3 xla/test/test_train_mp_imagenet.py --fake_data --model=resnet50 --num_epochs=1

gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "git clone https://github.com/tgisaturday/dalle-lightning.git"

gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "git clone https://github.com/kaushikb11/minGPT.git"


gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "cd dalle-lightning && git pull"

gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "pip3 uninstall pytorch-lightning"

gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "pip3 install -r dalle-lightning/requirements.txt"

gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "pip3 install git+https://github.com/tgisaturday/pytorch-lightning.git"

gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "pip3 install git+https://github.com/kaushikb11/pytorch-lightning.git@f1d0b655314c5fa7702e2a9068ba05a3093dbaad"
  
gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "sudo apt-get -y update && sudo apt-get -y install nfs-common"


gcloud alpha compute tpus tpu-vm ssh ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --worker=all \
  --command "sudo mkdir -p /datasets && sudo mount 10.46.147.34:/hyperdata /datasets"

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-32 --restart-tpuvm-pod-server -- python3 dalle-lightning/train_vae.py --use_tpus --model vqvae --fake_data 

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-64 --restart-tpuvm-pod-server -- python3 dalle-lightning/train_vae.py --use_tpus --model vqgan --fake_data --debug --xla_stat 

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-512 --restart-tpuvm-pod-server -- python3 dalle-lightning/train_vae.py --use_tpus --fake_data --model vqvae --debug --xla_stat 

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-256 --restart-tpuvm-pod-server -- python3 dalle-lightning/train_vae.py --use_tpus --fake_data --model vqvae --debug --xla_stat 

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-256 --restart-tpuvm-pod-server -- python3 dalle-lightning/train_dalle.py --use_tpus --fake_data --debug --xla_stat 

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-128 --restart-tpuvm-pod-server -- python3 dalle-lightning/main.py --use_tpus --refresh_rate 1 --fake_data --disc_start 1

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-128 --restart-tpuvm-pod-server -- python3 minGPT/benchmark.py --n_layer 14 --n_head 16 --n_embd 3072 --precision 16 --limit_train_batches 120

python3 -m torch_xla.distributed.xla_dist --tpu=vae-test -- python3 dalle-lightning/main.py --use_tpus --refresh_rate 1 --disc_start 1

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod --restart-tpuvm-pod-server -- python3 dalle-lightning/train_vae.py --use_tpus --refresh_rate 1 --train_dir /datasets/coco_train/ --val_dir /datasets/coco_val/ --disc_start 1

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-64 --restart-tpuvm-pod-server -- python3 dalle-lightning/train_vae.py--use_tpus --refresh_rate 1 --train_dir /datasets/coco_train/ --val_dir /datasets/coco_val/ --disc_start 1

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-128 --restart-tpuvm-pod-server -- python3 dalle-lightning/train_vae.py --use_tpus --refresh_rate 1 --train_dir /datasets/coco_train/ --val_dir /datasets/coco_val/ --disc_start 1


python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-256 --restart-tpuvm-pod-server -- python3 /home/taehoon.kim/taming-transformers-tpu/main.py --use_tpus --refresh_rate 1 --train_dir /datasets/coco_train/ --val_dir /datasets/coco_val/ --disc_start 1

gcloud compute --project=lgai-vision-tpu instances create pod-ctrl-32\
  --zone=europe-west4-a  \
  --machine-type=n1-standard-1  \
  --image-family=torch-xla \
  --image-project=ml-images  \
  --boot-disk-size=200GB \
  --scopes=https://www.googleapis.com/auth/cloud-platform


gcloud compute config-ssh
conda activate torch-xla-1.8.1

export TPU_NAME=tpu-vm-pod-32




python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-32 --restart-tpuvm-pod --env LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4  -- python3 /home/taehoon.kim/vqgan/main.py --use_tpus


----------------------


export PROJECT_ID=lgai-vision-tpu
export TPU_NAME=tpu-vm-pod-128
export ZONE=europe-west4-a
export RUNTIME_VERSION=v2-alpha

gcloud alpha compute tpus tpu-vm create ${TPU_NAME} \
--zone ${ZONE} --project ${PROJECT_ID} --accelerator-type v3-256 \
--version ${RUNTIME_VERSION}  --reserved --metadata startup-script='#! /bin/bash
cd /home/taehoon.kim/
mkdir coco_bucket
gcsfuse lgaivision-coco-eu coco_bucket
mkdir coco
cp coco_bucket/train2017.zip coco/
cd coco
unzip train2017.zip
cd ..
cp -r coco_bucket/taming-transformers/ /home/taehoon.kim/ 
fusermount -u /home/taehoon.kim/coco_bucket/

cd taming-transformers
pip3 install -r requirements.txt
cd ..
mkdir /home/taehoon.kim/temp/
chmod -R 777 /home/taehoon.kim/coco_bucket
chmod -R 777 /home/taehoon.kim/taming-transformers/
chmod -R 777 /home/taehoon.kim/coco
chmod -R 777 /home/taehoon.kim/temp
EOF'


export VM_NAME=pod-ctrl-256
export ZONE=europe-west4-a



gcloud compute --project=lgai-vision-tpu instances create pod-ctrl-256 \
  --zone=europe-west4-a  \
  --machine-type=n1-standard-1  \
  --image-family=torch-xla \
  --image-project=ml-images  \
  --boot-disk-size=200GB \
  --scopes=https://www.googleapis.com/auth/cloud-platform

gcloud compute ssh pod-ctrl-256 --zone=europe-west4-a

gcloud compute config-ssh

conda activate torch-xla-1.8.1

python3 -m torch_xla.distributed.xla_dist --tpu=tpu-vm-pod-256 --restart-tpuvm-pod --env LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc.so.4  -- python3 /home/taehoon.kim/taming-transformers/main.py --base /home/taehoon.kim/taming-transformers/configs/coco_vqgan.yaml -t True --num_sanity_val_steps=0 --tpu_cores=8 --precision=16 --checkpoint_callback=False


